{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTh5ZBg8MIx7"
      },
      "source": [
        "# Task di Segmentazione tramite Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgkv-QbQMeui"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAWaegY9QQro"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "\n",
        "#Access Google Drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYY2MFtbRUZS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q8BG1lJMdgf"
      },
      "outputs": [],
      "source": [
        "import tifffile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joQZpXfHPscD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8lumAdtSqXq"
      },
      "source": [
        "# **Esplorazione Dataset**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUywxnoENgpI"
      },
      "source": [
        "## Dataset Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGOi-wl-KMFg"
      },
      "source": [
        "**Composizione del dataset per il training**\n",
        "\n",
        "\n",
        "*   **images:** Contiene 1000 immagini nei formati TIFF, TIF, e PNG.\n",
        "Queste immagini rappresentano le immagini originali delle cellule acquisite tramite microscopio.\n",
        "Sono utilizzate come input per addestrare la rete neurale U-Net, che dovrà imparare a segmentare le immagini future.\n",
        "*   **labels:** Contiene le maschere corrispondenti alle immagini presenti nella cartella images. (1000 totali)\n",
        "\n",
        "Ogni maschera è un'immagine segmentata che evidenzia le diverse parti dell'immagine originale, separando le cellule dal background e distinguendo ogni cellula come un'entità unica.\n",
        "\n",
        "La maschera rappresenta la ground truth, ovvero ciò che ci aspettiamo che la U-Net produca come output dopo il training.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xTbUX8rLob2"
      },
      "source": [
        "**Chiarificazione**\n",
        "\n",
        "Per ogni immagine presente nella cartella images, esiste una corrispondente maschera nella cartella labels.\n",
        "Le due cartelle sono allineate, ovvero ogni immagine in images ha la sua maschera associata con lo stesso nome di file nella cartella labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlsyi_EXLsrd"
      },
      "source": [
        "**obiettivo principale**\n",
        "\n",
        "Durante il training:\n",
        "\n",
        "La rete neurale prende come input le immagini dalla cartella images.\n",
        "Confronta il proprio output con le maschere nella cartella labels per imparare a:\n",
        "Identificare le cellule.\n",
        "Separarle dallo sfondo.\n",
        "Distinguere le diverse cellule tra loro.\n",
        "Alla fine del training, la rete sarà in grado di segmentare nuove immagini di cellule in modo automatico, producendo una maschera simile a quelle nella cartella labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kegslm31Eve2"
      },
      "outputs": [],
      "source": [
        "# Paths to the image and mask\n",
        "image_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/images/cell_00459.tif\"\n",
        "mask_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/labels/cell_00459_label.tiff\"\n",
        "\n",
        "# Load the image and mask\n",
        "image = tifffile.imread(image_path)\n",
        "mask = tifffile.imread(mask_path)\n",
        "\n",
        "# Display basic information about the image and mask\n",
        "print(\"Image Shape:\", image.shape)\n",
        "print(\"Mask Shape:\", mask.shape)\n",
        "print(\"Unique Values in Mask:\", np.unique(mask)[:10], \"...\")  # Preview unique labels\n",
        "\n",
        "# Plot the image and its mask side by side\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap=\"gray\")\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Corresponding mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask, cmap=\"nipy_spectral\")  # Colormap for distinguishing labels\n",
        "plt.title(\"Segmentation Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8IeThslIEKP"
      },
      "outputs": [],
      "source": [
        "# Define the folder path\n",
        "folder_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/labels\"\n",
        "\n",
        "# Count the number of image files in the folder\n",
        "try:\n",
        "    # List all files in the folder and filter for common image extensions\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.tif', '.tiff'))]\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    print(f\"Number of images in the folder '{folder_path}': {num_images}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The folder '{folder_path}' does not exist. Please check the path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vED5HA6sHlNj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/images\"\n",
        "\n",
        "# Count the number of image files in the folder\n",
        "try:\n",
        "    # List all files in the folder and filter for common image extensions\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.tif', '.tiff', '.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    print(f\"Number of images in the folder '{folder_path}': {num_images}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The folder '{folder_path}' does not exist. Please check the path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku3mTmADJMYs"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Paths to the image and mask\n",
        "image_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/images/cell_00188.png\"\n",
        "mask_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/labels/cell_00188_label.tiff\"\n",
        "\n",
        "# Load the image and mask using skimage\n",
        "image = imread(image_path)\n",
        "mask = imread(mask_path)\n",
        "\n",
        "# Display basic information about the image and mask\n",
        "print(\"Image Shape:\", image.shape)\n",
        "print(\"Image Data Type:\", image.dtype)\n",
        "print(\"Mask Shape:\", mask.shape)\n",
        "print(\"Mask Data Type:\", mask.dtype)\n",
        "print(\"Unique Values in Mask:\", np.unique(mask)[:10], \"...\")  # Preview unique labels\n",
        "\n",
        "# Plot the image and its mask side by side\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap=\"gray\")\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "# Corresponding mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask, cmap=\"nipy_spectral\")  # Colormap for distinguishing labels\n",
        "plt.title(\"Segmentation Mask\")\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV_nWX8MNlam"
      },
      "source": [
        "## Dataset Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_ncbqG3OMEB"
      },
      "source": [
        "Questo dataset verrà utilizzato per valutare l'accuratezza della segmentazione ottenuta dalla U-Net dopo il processo di addestramento.\n",
        "\n",
        "In particolare, per testare le prestazioni della rete, abbiamo a disposizione 50 nuove immagini, ciascuna associata alla rispettiva label (maschera di riferimento).\n",
        "\n",
        "Queste immagini, mai utilizzate durante l'addestramento, vengono inserite nella rete come input. Successivamente, confrontiamo le segmentazioni prodotte dalla rete con le labels fornite nel dataset, in modo da misurare quanto l'output della rete si avvicini alla segmentazione attesa. Questo confronto ci permette di valutare la capacità della rete di generalizzare su dati non visti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cnBZ7C7N4He"
      },
      "outputs": [],
      "source": [
        "# Define the folder path\n",
        "folder_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Testing/Public/labels\"\n",
        "\n",
        "# Count the number of image files in the folder\n",
        "try:\n",
        "    # List all files in the folder and filter for common image extensions\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.tif', '.tiff'))]\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    print(f\"Number of images in the folder '{folder_path}': {num_images}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The folder '{folder_path}' does not exist. Please check the path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ObcLmcbOGAf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define the folder path\n",
        "folder_path = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Testing/Public/images\"\n",
        "\n",
        "# Count the number of image files in the folder\n",
        "try:\n",
        "    # List all files in the folder and filter for common image extensions\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.tif', '.tiff', '.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "    num_images = len(image_files)\n",
        "\n",
        "    print(f\"Number of images in the folder '{folder_path}': {num_images}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The folder '{folder_path}' does not exist. Please check the path.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jih9I916P8vx"
      },
      "source": [
        "# Preprocessing Dataset Training\n",
        "In questa sezione puliamo e prepariamo il dataset per il training della rete. In particolare uniformiamo la grandezza delle immagini e le mettiamo in scala di grigio. inoltre ci assicuriamo che le maschere siano della stessa grandezza delle immagini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dXvSx2Os1xd"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Funzione per caricare immagini in scala di grigi e abbinare dinamicamente le etichette\n",
        "def load_grayscale_images_with_labels(image_dir, label_dir):\n",
        "    \"\"\"\n",
        "    Carica e preprocessa immagini in scala di grigi con le etichette corrispondenti.\n",
        "    Solo le immagini con un'etichetta valida vengono incluse.\n",
        "\n",
        "    Args:\n",
        "        image_dir (str): Path alla directory contenente le immagini.\n",
        "        label_dir (str): Path alla directory contenente le etichette.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Immagini preprocessate in scala di grigi.\n",
        "        np.ndarray: Etichette preprocessate.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "    print(f\"Caricamento immagini dalla directory: {image_dir}\")\n",
        "    print(f\"Caricamento etichette dalla directory: {label_dir}\")\n",
        "\n",
        "    # Ottieni tutti i file delle etichette disponibili\n",
        "    label_files = {os.path.splitext(f)[0]: f for f in os.listdir(label_dir)}\n",
        "\n",
        "    for filename in sorted(os.listdir(image_dir)):\n",
        "        # Controlla estensioni valide per le immagini\n",
        "        if filename.lower().endswith(('.tiff', '.tif', '.png', '.jpg', '.jpeg', '.bmp')):\n",
        "            # Estrai il nome base del file senza estensione\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            # Cerca il file di etichetta corrispondente\n",
        "            label_filename = label_files.get(base_name + \"_label\")\n",
        "\n",
        "            if label_filename:\n",
        "                try:\n",
        "                    # Carica e preprocessa l'immagine\n",
        "                    img = Image.open(os.path.join(image_dir, filename)).convert('L')  # Scala di grigi\n",
        "                    img = img.resize((256, 256), Image.Resampling.LANCZOS)  # Resize\n",
        "                    img = np.array(img, dtype=np.float32) / 255.0  # Normalizza tra [0, 1]\n",
        "\n",
        "                    # Carica e preprocessa l'etichetta\n",
        "                    label_path = os.path.join(label_dir, label_filename)\n",
        "                    lbl = Image.open(label_path).convert('1')  # Binario\n",
        "                    lbl = lbl.resize((256, 256), Image.Resampling.NEAREST)  # Resize\n",
        "                    lbl = np.array(lbl, dtype=np.uint8)  # Converte in interi 0 o 1\n",
        "\n",
        "                    # Aggiungi immagine ed etichetta alla lista\n",
        "                    images.append(img[..., np.newaxis])  # Aggiungi dimensione canale\n",
        "                    labels.append(lbl[..., np.newaxis])  # Aggiungi dimensione canale\n",
        "                    print(f\"Immagine ed etichetta caricate con successo: {filename}\")\n",
        "                except (IOError, UnidentifiedImageError) as e:\n",
        "                    print(f\"Errore nel caricamento di immagine o etichetta per {filename}: {e}\")\n",
        "            else:\n",
        "                print(f\"Etichetta non trovata per l'immagine: {filename}\")\n",
        "        else:\n",
        "            print(f\"File ignorato (estensione non valida): {filename}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Funzione per caricare il dataset\n",
        "def load_dataset(image_dir, label_dir):\n",
        "    images, labels = load_grayscale_images_with_labels(image_dir, label_dir)\n",
        "    print(f\"Numero di immagini caricate: {len(images)}\")\n",
        "    print(f\"Numero di etichette caricate: {len(labels)}\")\n",
        "    return tf.data.Dataset.from_tensor_slices((images, labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpJwlAHBs3Au"
      },
      "outputs": [],
      "source": [
        "# Imposta i percorsi direttamente nel codice\n",
        "PERCORSO_TRAINING_IMMAGINI = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/images\"\n",
        "PERCORSO_TRAINING_LABELS = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Training/labels\"\n",
        "PERCORSO_TUNING_IMMAGINI = '/content/gdrive/MyDrive/NeurIPS22-CellSeg/Tuning/images'\n",
        "PERCORSO_TUNING_LABELS = '/content/gdrive/MyDrive/NeurIPS22-CellSeg/Tuning/labels'\n",
        "\n",
        "PERCORSO_TEST_IMMAGINI = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Testing/Public/images\"\n",
        "PERCORSO_TEST_LABELS = \"/content/gdrive/MyDrive/NeurIPS22-CellSeg/Testing/Public/labels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_pvi39RtSry"
      },
      "outputs": [],
      "source": [
        "# Carica i dataset di addestramento e tuning\n",
        "train_dataset = load_dataset(PERCORSO_TRAINING_IMMAGINI, PERCORSO_TRAINING_LABELS)\n",
        "tuning_dataset = load_dataset(PERCORSO_TUNING_IMMAGINI, PERCORSO_TUNING_LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnMUfOTZqekp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Funzione per plottare un campione dal dataset\n",
        "def plot_sample(dataset, title=\"Sample\"):\n",
        "    \"\"\"\n",
        "    Plotta un campione dal dataset, mostrando immagine e maschera corrispondente.\n",
        "\n",
        "    Args:\n",
        "        dataset (tf.data.Dataset): Il dataset da cui estrarre i campioni.\n",
        "        title (str): Titolo del plot.\n",
        "    \"\"\"\n",
        "    # Estrai un campione dal dataset\n",
        "    for image, label in dataset.take(1):  # Prendi un batch (immagine e maschera)\n",
        "        image = image.numpy().squeeze()  # Rimuove dimensioni extra\n",
        "        label = label.numpy().squeeze()  # Rimuove dimensioni extra\n",
        "\n",
        "        # Plot\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        # Immagine originale\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f\"{title} - Immagine originale\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Maschera corrispondente\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(label, cmap='gray')\n",
        "        plt.title(f\"{title} - Maschera\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvCigNmbAct5"
      },
      "outputs": [],
      "source": [
        "# Plotta un campione dal dataset di training\n",
        "print(\"Campione dal dataset di training:\")\n",
        "plot_sample(train_dataset, title=\"Training\")\n",
        "\n",
        "# Plotta un campione dal dataset di tuning\n",
        "print(\"Campione dal dataset di tuning:\")\n",
        "plot_sample(tuning_dataset, title=\"Tuning\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxmwPsIt5FZ1"
      },
      "source": [
        "# Unet training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su4nHevYdLU0"
      },
      "outputs": [],
      "source": [
        "def unet_multiclass_segmentation(input_size=(256, 256, 1)):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = layers.BatchNormalization()(c1)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = layers.BatchNormalization()(c2)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = layers.BatchNormalization()(c3)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = layers.BatchNormalization()(c4)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = layers.BatchNormalization()(c5)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = layers.BatchNormalization()(c6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = layers.BatchNormalization()(c7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = layers.BatchNormalization()(c8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = layers.BatchNormalization()(c9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    # Final output layer for binary segmentation\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid', padding='same')(c9)\n",
        "\n",
        "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
        "    return model\n",
        "\n",
        "model = unet_multiclass_segmentation(input_size=(256, 256, 1))\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCk4MNJd210E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Train the model with augmented data\n",
        "history = model.fit(\n",
        "    train_dataset.batch(32),\n",
        "    validation_data=tuning_dataset.batch(32),\n",
        "    epochs=8,\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJWlyChW5eb-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7qHP5sg5jZG"
      },
      "outputs": [],
      "source": [
        "# Save the model in the local runtime\n",
        "model.save(\"/content/gdrive/MyDrive/trained_unet_model_V1.keras\")\n",
        "print(\"Model saved locally as 'trained_unet_model.keras'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeWR7r8rGsys"
      },
      "source": [
        "# TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt-hye-2B8tm"
      },
      "outputs": [],
      "source": [
        "# Carica i dataset di addestramento e tuning\n",
        "test_dataset = load_dataset(PERCORSO_TEST_IMMAGINI, PERCORSO_TEST_LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6diocJOkKEy6"
      },
      "outputs": [],
      "source": [
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6acnwdIROfr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = tf.keras.models.load_model(\"/content/gdrive/MyDrive/trained_unet_model_V1.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEzlnsgCNbuB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check the structure of the dataset\n",
        "print(\"Dataset element spec:\", test_dataset.element_spec)\n",
        "\n",
        "# Iterate through a few samples to inspect the data\n",
        "for i, (image, mask) in enumerate(test_dataset.take(1)):  # Take one sample\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    print(\"Image shape:\", image.shape, \"dtype:\", image.dtype)\n",
        "    print(\"Mask shape:\", mask.shape, \"dtype:\", mask.dtype)\n",
        "\n",
        "    # Visualize the image and mask\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image.numpy().squeeze(), cmap='gray')  # Squeeze to remove the channel dimension\n",
        "    plt.title(\"Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(mask.numpy().squeeze(), cmap='gray')  # Squeeze to remove the channel dimension\n",
        "    plt.title(\"Mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbJMA9FXVtcK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize counters for total pixels and correctly predicted pixels\n",
        "total_pixels = 0\n",
        "correct_pixels = 0\n",
        "\n",
        "# Iterate through the test dataset\n",
        "for i, (image, mask) in enumerate(test_dataset):\n",
        "    # Predict the mask for the image\n",
        "    image_batch = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    predicted_mask = loaded_model.predict(image_batch)\n",
        "\n",
        "    # Post-process the prediction (if needed)\n",
        "    predicted_mask_binary = predicted_mask.squeeze().astype(\"uint8\")  # Binary mask (already 0 or 1)\n",
        "\n",
        "    # Ensure ground truth mask is binary (if necessary)\n",
        "    true_mask_binary = mask.numpy().squeeze().astype(\"uint8\")\n",
        "\n",
        "    # Count correct pixels\n",
        "    correct_pixels += np.sum(predicted_mask_binary == true_mask_binary)\n",
        "    total_pixels += np.prod(true_mask_binary.shape)  # Total pixels in the mask\n",
        "\n",
        "# Calculate pixel-wise accuracy\n",
        "pixel_accuracy = correct_pixels / total_pixels\n",
        "print(f\"Final Pixel-Wise Segmentation Accuracy: {pixel_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fwh1ZEWAXXSg"
      },
      "outputs": [],
      "source": [
        "for i, (image, mask) in enumerate(test_dataset):\n",
        "    print(f\"Processing image {i + 1}...\")\n",
        "\n",
        "    # Predict the mask for the current image\n",
        "    image_batch = tf.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    predicted_mask = loaded_model.predict(image_batch)  # Raw predictions\n",
        "\n",
        "    # Plot the original image, ground truth mask, and predicted mask\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Original Image\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(image.numpy().squeeze(), cmap='gray')\n",
        "    plt.title(f\"Original Image {i + 1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Ground Truth Mask\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(mask.numpy().squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "    plt.title(f\"Ground Truth Mask {i + 1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted Mask\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(predicted_mask.squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Predicted Mask {i + 1} (Raw)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Show the plots\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}